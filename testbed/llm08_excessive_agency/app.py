"""
LLM08: Excessive Agency - Synthetic Vulnerable Application
This module contains intentional vulnerabilities for testing purposes.
"""

import os
import subprocess
from openai import OpenAI

client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))


# VULN:LLM08:CRITICAL:LINE=16 - Auto-execution of LLM-generated code
def vulnerable_auto_execute(user_request: str) -> str:
    """Vulnerable: Automatically executes code generated by LLM."""
    prompt = f"Write Python code to: {user_request}. Output only code, no explanation."
    response = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}]
    )
    code = response.choices[0].message.content

    # VULNERABLE - auto-execution without human review
    exec(code)
    return "Code executed"


# VULN:LLM08:HIGH:LINE=30 - Unrestricted database write access
class VulnerableDBAgent:
    """Vulnerable: LLM agent with full database write access."""

    def __init__(self, db_connection):
        self.db = db_connection

    def process_request(self, user_request: str) -> str:
        prompt = f"Generate SQL to: {user_request}"
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}]
        )
        sql = response.choices[0].message.content

        # VULNERABLE - unrestricted write access
        self.db.execute(sql)
        self.db.commit()
        return "Query executed"


# VULN:LLM08:CRITICAL:LINE=51 - Agent with system-level access
class VulnerableSystemAgent:
    """Vulnerable: Agent can execute system commands."""

    def execute_task(self, task: str) -> str:
        prompt = f"What shell command should I run to: {task}?"
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}]
        )
        command = response.choices[0].message.content

        # VULNERABLE - system-level access without approval
        result = subprocess.run(command, shell=True, capture_output=True, text=True)
        return result.stdout


# VULN:LLM08:HIGH:LINE=69 - Autonomous financial transactions
class VulnerableFinanceAgent:
    """Vulnerable: Agent can make financial transactions autonomously."""

    def __init__(self, payment_api):
        self.payment = payment_api

    def process_request(self, user_request: str) -> str:
        prompt = f"Should I process this payment request: {user_request}? If yes, respond with the amount."
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}]
        )
        decision = response.choices[0].message.content

        # VULNERABLE - no human approval for financial transactions
        if "yes" in decision.lower():
            amount = self._extract_amount(decision)
            self.payment.transfer(amount)
        return decision

    def _extract_amount(self, text: str) -> float:
        return 100.0  # Simplified


# VULN:LLM08:HIGH:LINE=95 - Agent with email/communication access
class VulnerableEmailAgent:
    """Vulnerable: Agent can send emails without approval."""

    def __init__(self, email_client):
        self.email = email_client

    def handle_request(self, request: str) -> str:
        prompt = f"Draft and send an email for: {request}"
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}]
        )
        email_content = response.choices[0].message.content

        # VULNERABLE - sending emails without human review
        self.email.send(email_content)
        return "Email sent"


# VULN:LLM08:MEDIUM:LINE=115 - No action logging/audit trail
class VulnerableUnloggedAgent:
    """Vulnerable: Agent actions are not logged."""

    def perform_action(self, action: str) -> str:
        prompt = f"Perform this action: {action}"
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}]
        )

        # VULNERABLE - no audit trail
        result = self._execute(response.choices[0].message.content)
        return result

    def _execute(self, instruction: str) -> str:
        # Execute without logging
        return "Done"


# SAFE: Human-in-the-loop agent (for comparison)
class SafeApprovalAgent:
    """Safe: Requires human approval for sensitive actions."""

    def __init__(self, approval_callback):
        self.approve = approval_callback

    def process_request(self, request: str) -> str:
        prompt = f"Suggest an action for: {request}"
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}]
        )
        suggested_action = response.choices[0].message.content

        # Require human approval
        if self.approve(suggested_action):
            return self._execute_safe(suggested_action)
        return "Action rejected by human"

    def _execute_safe(self, action: str) -> str:
        # Log action
        # Execute in sandbox
        return "Done safely"
