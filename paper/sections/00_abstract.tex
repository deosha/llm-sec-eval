\begin{abstract}
LLM-integrated applications introduce a new class of vulnerabilities where user input influences program behavior through LLM transformations. Traditional taint analysis fails at LLM API boundaries because the model generates outputs that are syntactically independent of inputs, breaking data flow tracking. We introduce \emph{semantic influence}---a taint analysis extension that models how user-controlled data propagates through LLM calls to reach dangerous sinks. Our key insight is that while LLM outputs have no syntactic dependency on inputs, they remain semantically controllable by adversaries through prompt injection. We formalize influence strength with position-dependent decay (prompt: 0.85, context: 0.70, system: 0.50) and multi-hop attenuation. We implement this model in a Python static analyzer supporting major LLM SDKs. On a benchmark of 73 OWASP LLM vulnerabilities, we achieve 76\% precision and 60\% recall, substantially outperforming Semgrep (F1: 0.127) and Bandit (F1: 0.463). On real security commits from production LLM frameworks, we achieve 100\% precision with zero false positives. Our tool is available at \texttt{[URL]}.
\end{abstract}
