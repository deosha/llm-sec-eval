================================================================================
                    FULL EVALUATION COMPARISON - AI SECURITY CLI
================================================================================

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
                    PART 1: SYNTHETIC TESTBED (Ground Truth)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

AGGREGATE METRICS
┌───────────┬───────────┬────────┬────────┬─────┬─────┬─────┐
│ Tool      │ Precision │ Recall │ F1     │ TP  │ FP  │ FN  │
├───────────┼───────────┼────────┼────────┼─────┼─────┼─────┤
│ AI-Sec    │ 17.0%     │ 60.9%  │ 26.5%  │ 39  │ 191 │ 25  │
│ Semgrep   │ 83.3%     │ 7.8%   │ 14.3%  │ 5   │ 1   │ 59  │
│ Bandit    │ 69.2%     │ 42.2%  │ 52.4%  │ 27  │ 12  │ 37  │
└───────────┴───────────┴────────┴────────┴─────┴─────┴─────┘

PER-CATEGORY F1 SCORES
┌──────────┬─────────┬─────────┬────────┬─────────────────────────────────────┐
│ Category │ AI-Sec  │ Semgrep │ Bandit │ Notes                               │
├──────────┼─────────┼─────────┼────────┼─────────────────────────────────────┤
│ LLM01    │ 25.0%   │ 0.0%    │ 33.3%  │ Prompt Injection                    │
│ LLM02    │ 0.0%    │ 40.0%   │ 80.0%  │ Insecure Output                     │
│ LLM03    │ 0.0%    │ 0.0%    │ 54.5%  │ Training Poisoning                  │
│ LLM04    │ 27.9%   │ 0.0%    │ 0.0%   │ Model DoS ★ UNIQUE TO AI-SEC        │
│ LLM05    │ 44.4%   │ 0.0%    │ 63.2%  │ Supply Chain                        │
│ LLM06    │ 28.6%   │ 0.0%    │ 60.0%  │ Sensitive Info                      │
│ LLM07    │ 18.2%   │ 25.0%   │ 76.9%  │ Insecure Plugin                     │
│ LLM08    │ 22.2%   │ 50.0%   │ 66.7%  │ Excessive Agency                    │
│ LLM09    │ 31.8%   │ 0.0%    │ 0.0%   │ Overreliance ★ UNIQUE TO AI-SEC     │
│ LLM10    │ 37.8%   │ 0.0%    │ 0.0%   │ Model Theft ★ UNIQUE TO AI-SEC      │
└──────────┴─────────┴─────────┴────────┴─────────────────────────────────────┘

RECALL BY CATEGORY (% of vulnerabilities found)
┌──────────┬─────────┬─────────┬────────┐
│ Category │ AI-Sec  │ Semgrep │ Bandit │
├──────────┼─────────┼─────────┼────────┤
│ LLM01    │ 100%    │ 0%      │ 20%    │
│ LLM02    │ 0%      │ 29%     │ 86%    │
│ LLM03    │ 0%      │ 0%      │ 60%    │
│ LLM04    │ 100%    │ 0%      │ 0%     │
│ LLM05    │ 29%     │ 0%      │ 86%    │
│ LLM06    │ 71%     │ 0%      │ 43%    │
│ LLM07    │ 14%     │ 14%     │ 71%    │
│ LLM08    │ 100%    │ 33%     │ 50%    │
│ LLM09    │ 100%    │ 0%      │ 0%     │
│ LLM10    │ 100%    │ 0%      │ 0%     │
└──────────┴─────────┴─────────┴────────┘

SECURITY AUDIT ACCURACY
┌────────────────────┬────────┐
│ Metric             │ Value  │
├────────────────────┼────────┤
│ Exact Match        │ 26/29  │
│ Accuracy           │ 89.7%  │
│ Over-detection     │ 3      │
│ Under-detection    │ 0      │
└────────────────────┴────────┘

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
                    PART 2: REAL-WORLD REPOSITORIES (5 Repos)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

FINDING COUNTS
┌─────────────┬──────────┬────────────────┬─────────┬─────────────┐
│ Repository  │ AI-Sec   │ Bandit (H+M)   │ Ratio   │ LOC         │
├─────────────┼──────────┼────────────────┼─────────┼─────────────┤
│ LangChain   │ 313      │ 6              │ 52x     │ 53,810      │
│ LlamaIndex  │ 499      │ 6              │ 83x     │ 60,344      │
│ Haystack    │ 322      │ 18             │ 18x     │ ~40,000     │
│ LiteLLM     │ 5,661    │ 73             │ 78x     │ ~150,000    │
│ DSPy        │ 218      │ 25             │ 9x      │ ~25,000     │
├─────────────┼──────────┼────────────────┼─────────┼─────────────┤
│ TOTAL       │ 7,013    │ 128            │ 55x     │ ~329,000    │
└─────────────┴──────────┴────────────────┴─────────┴─────────────┘

AI-SEC SEVERITY DISTRIBUTION (All 5 Repos)
┌─────────────┬──────────┬──────┬────────┬─────┐
│ Repository  │ CRITICAL │ HIGH │ MEDIUM │ LOW │
├─────────────┼──────────┼──────┼────────┼─────┤
│ LangChain   │ 20       │ 238  │ 26     │ 29  │
│ LlamaIndex  │ 130      │ 250  │ 30     │ 89  │
│ Haystack    │ 11       │ 291  │ 11     │ 9   │
│ LiteLLM     │ 582      │ 3868 │ 776    │ 435 │
│ DSPy        │ 33       │ 139  │ 24     │ 22  │
├─────────────┼──────────┼──────┼────────┼─────┤
│ TOTAL       │ 776      │ 4786 │ 867    │ 584 │
│ Percentage  │ 11.1%    │ 68.2%│ 12.4%  │ 8.3%│
└─────────────┴──────────┴──────┴────────┴─────┘

SECURITY POSTURE AUDIT
┌─────────────┬───────┬─────────────┐
│ Repository  │ Score │ Maturity    │
├─────────────┼───────┼─────────────┤
│ LangChain   │ 33.1% │ Developing  │
│ LlamaIndex  │ 37.6% │ Developing  │
│ Haystack    │ 18.8% │ Initial     │
│ LiteLLM     │ 28.3% │ Developing  │
│ DSPy        │ 19.6% │ Initial     │
├─────────────┼───────┼─────────────┤
│ Average     │ 27.5% │ Developing  │
└─────────────┴───────┴─────────────┘

CATEGORY DISTRIBUTION (7,013 Total Findings)
┌────────────────────────────────┬───────┬────────┐
│ Category                       │ Count │ %      │
├────────────────────────────────┼───────┼────────┤
│ LLM05: Supply Chain            │ 3,131 │ 44.6%  │
│ LLM02: Insecure Output         │ 1,144 │ 16.3%  │
│ LLM04: Model DoS               │ 1,000 │ 14.3%  │
│ LLM09: Overreliance            │ 920   │ 13.1%  │
│ LLM08: Excessive Agency        │ 657   │ 9.4%   │
│ LLM01: Prompt Injection        │ 114   │ 1.6%   │
│ LLM03: Training Poisoning      │ 22    │ 0.3%   │
│ LLM10: Model Theft             │ 15    │ 0.2%   │
│ LLM06: Sensitive Info          │ 6     │ 0.1%   │
│ LLM07: Insecure Plugin         │ 4     │ 0.1%   │
└────────────────────────────────┴───────┴────────┘

CONFIDENCE SCORE DISTRIBUTION
┌─────────────┬────────────┬────────────┬────────────┐
│ Repository  │ High (≥0.9)│ Med (0.75) │ Low (0.7)  │
├─────────────┼────────────┼────────────┼────────────┤
│ LangChain   │ 195 (62%)  │ 28 (9%)    │ 90 (29%)   │
│ LlamaIndex  │ 94 (19%)   │ 116 (23%)  │ 289 (58%)  │
│ Haystack    │ 279 (87%)  │ 11 (3%)    │ 32 (10%)   │
│ LiteLLM     │ 2312 (41%) │ 1105 (20%) │ 2244 (40%) │
│ DSPy        │ 83 (38%)   │ 38 (17%)   │ 97 (45%)   │
└─────────────┴────────────┴────────────┴────────────┘

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
                    PART 3: KEY TAKEAWAYS
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

STRENGTHS
✓ 60.9% recall on LLM-specific vulnerabilities (vs 7.8% Semgrep, 42.2% Bandit)
✓ UNIQUE detection for LLM04, LLM09, LLM10 (0% by other tools)
✓ 89.7% security audit accuracy
✓ 55x more LLM-specific findings than Bandit on real-world repos
✓ 79% of findings are HIGH or CRITICAL severity

WEAKNESSES
✗ 17% precision (high false positive rate)
✗ Lower overall F1 than Bandit (26.5% vs 52.4%)
✗ 0% recall on LLM02 (Insecure Output) and LLM03 (Training Poisoning)

UNIQUE VALUE PROPOSITION
┌────────────────────────────────────────────────────────────────────┐
│ AI Security CLI is the ONLY tool that detects:                     │
│ • LLM04: Model Denial of Service (resource exhaustion attacks)     │
│ • LLM09: Overreliance (missing validation of LLM outputs)          │
│ • LLM10: Model Theft (model extraction vulnerabilities)            │
│                                                                    │
│ Traditional SAST tools have 0% coverage for these categories.      │
└────────────────────────────────────────────────────────────────────┘

Generated: 2026-01-08
Repositories: LangChain, LlamaIndex, Haystack, LiteLLM, DSPy
Total LOC analyzed: ~329,000
